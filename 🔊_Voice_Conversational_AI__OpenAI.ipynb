{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xyu9NciO8Ai6",
        "outputId": "69fa94ff-d313-49f1-9bf1-19f844169547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "added 7 packages, and audited 416 packages in 3s\n",
            "\n",
            "40 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 0 vulnerabilities\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "npm notice \n",
            "npm notice New major version of npm available! 9.2.0 -> 10.6.0\n",
            "npm notice Changelog: <https://github.com/npm/cli/releases/tag/v10.6.0>\n",
            "npm notice Run `npm install -g npm@10.6.0` to update!\n",
            "npm notice \n"
          ]
        }
      ],
      "source": [
        "# !pip -q install utils\n",
        "# !pip -q install openai\n",
        "# !pip -q install gradio\n",
        "# !pip -q install langchain\n",
        "# !pip -q install streamlit\n",
        "# !pip -q install python-dotenv\n",
        "# !pip -q install streamlit_float\n",
        "# !pip -q install audio_recorder_streamlit\n",
        "\n",
        "\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uS4TlkNQ7-es"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import uuid\n",
        "import time\n",
        "import openai\n",
        "# import pygame\n",
        "# import librosa\n",
        "import base64\n",
        "# import gradio as gr\n",
        "import streamlit as st\n",
        "\n",
        "from openai import OpenAI\n",
        "from base64 import b64decode\n",
        "# from google.colab import userdata\n",
        "from typing import Optional, Tuple\n",
        "from IPython.display import Javascript, Audio\n",
        "# from google.colab import userdata, output\n",
        "\n",
        "from langchain import LLMChain # LLM\n",
        "from langchain.chat_models import ChatOpenAI # ChatModel\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "# from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain.memory import ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmWeEPpY7z7e"
      },
      "source": [
        "# Transcribe Class (ASR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZFzMG4bR24Sa"
      },
      "outputs": [],
      "source": [
        "# RECORD = \"\"\"\n",
        "#     const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "#     const b2text = blob => new Promise(resolve => {\n",
        "#       const reader = new FileReader()\n",
        "#       reader.onloadend = e => resolve(e.srcElement.result)\n",
        "#       reader.readAsDataURL(blob)\n",
        "#     })\n",
        "#     var record = time => new Promise(async resolve => {\n",
        "#       stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "#       recorder = new MediaRecorder(stream)\n",
        "#       chunks = []\n",
        "#       recorder.ondataavailable = e => chunks.push(e.data)\n",
        "#       recorder.start()\n",
        "#       await sleep(time)\n",
        "#       recorder.onstop = async ()=>{\n",
        "#         blob = new Blob(chunks)\n",
        "#         text = await b2text(blob)\n",
        "#         resolve(text)\n",
        "#       }\n",
        "#       recorder.stop()\n",
        "#     })\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1pKSErY8hfx",
        "outputId": "ad44fb33-a8b2-4fce-eb81-dc680f291f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting transcribe.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile transcribe.py\n",
        "\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "class Transcribe:\n",
        "\n",
        "    def __init__(self, api_key):\n",
        "        self.client = OpenAI(api_key=api_key)\n",
        "        self.path = './chatbot/transcribe'\n",
        "\n",
        "        if not os.path.exists(self.path):\n",
        "            os.makedirs(self.path)\n",
        "\n",
        "    def speech_to_text(self, audio):\n",
        "        with open(audio, 'rb') as audio_file:\n",
        "\n",
        "            transcription = self.client.audio.transcriptions.create(\n",
        "                model=\"whisper-1\",\n",
        "                file=audio_file,\n",
        "                response_format=\"text\"\n",
        "            )\n",
        "\n",
        "        return transcription\n",
        "\n",
        "    def save_file(self, audio_bytes):\n",
        "        unique_filename = str(uuid.uuid4()) + \".mp3\"\n",
        "        filepath = os.path.join(self.path, unique_filename)\n",
        "\n",
        "        with open(filepath,'wb') as f:\n",
        "            f.write(audio_bytes)\n",
        "\n",
        "        return filepath\n",
        "\n",
        "    def delete_file(self):\n",
        "        for file in os.listdir(self.path):\n",
        "            if file.endswith(\".mp3\"):\n",
        "                os.remove(os.path.join(self.path, file))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f_0fHcQ_TXX"
      },
      "source": [
        "# LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbGXwYQpJGS0",
        "outputId": "f226b149-c2f7-4098-da22-3ac8ee0bc21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting llmchain.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile llmchain.py\n",
        "\n",
        "# from langchain_core.memory import BaseMemory\n",
        "# from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "# from langchain_openai import ChatOpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "from langchain import LLMChain  # LLM\n",
        "from langchain import LLMChain\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "import streamlit as st\n",
        "\n",
        "@st.cache_resource\n",
        "class Langchain:\n",
        "    def __init__(self, api_key, model_name='gpt-4'):\n",
        "        self.llm = ChatOpenAI(temperature=0, api_key=api_key, model_name=model_name)\n",
        "        self.template = \"\"\"\n",
        "\n",
        "                        This is OpenAI\n",
        "\n",
        "                        Previous conversation:\n",
        "                        {history}\n",
        "\n",
        "                        Human: {question}\n",
        "\n",
        "                        Assistant:\n",
        "\n",
        "                        \"\"\"\n",
        "        self.prompt = PromptTemplate(\n",
        "            input_variables = [\"history\", \"question\"],\n",
        "            template = self.template\n",
        "        )\n",
        "        self.memory = ConversationBufferWindowMemory(k=5)\n",
        "        self.chain = self.create_chain()\n",
        "\n",
        "    def create_chain(self):\n",
        "        return LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=self.prompt,\n",
        "            # verbose=True,\n",
        "            memory=self.memory\n",
        "        )\n",
        "\n",
        "    def chat(self, question):\n",
        "        response = self.chain.run({\"question\": question})\n",
        "\n",
        "        return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5qyZc1x73Ih"
      },
      "source": [
        "# Voice Class (TTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9BS4bYM4sIr",
        "outputId": "72e9fd75-5221-4425-c1a2-dd42e25d3f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting voice.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile voice.py\n",
        "\n",
        "import base64\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "\n",
        "class Voice:\n",
        "\n",
        "    def __init__(self, api_key):\n",
        "        self.client = OpenAI(api_key=api_key)\n",
        "        self.path = './chatbot/voice'\n",
        "\n",
        "        if not os.path.exists(self.path):\n",
        "            os.makedirs(self.path)\n",
        "\n",
        "    def text_to_speech(self, transcript):\n",
        "        response = self.client.audio.speech.create(\n",
        "            model=\"tts-1-hd\",\n",
        "            voice=\"echo\",\n",
        "            input=transcript,\n",
        "        )\n",
        "\n",
        "        unique_filename = str(uuid.uuid4()) + \".mp3\"\n",
        "        filepath = os.path.join(self.path, unique_filename)\n",
        "        response.stream_to_file(filepath)\n",
        "\n",
        "        return filepath\n",
        "\n",
        "    def delete_file(self):\n",
        "        for file in os.listdir(self.path):\n",
        "            if file.endswith(\".mp3\"):\n",
        "                os.remove(os.path.join(self.path, file))\n",
        "\n",
        "    def autoplay_audio(self, file_path: str):\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            data = f.read()\n",
        "        b64 = base64.b64encode(data).decode(\"utf-8\")\n",
        "        md = f\"\"\"\n",
        "        <audio autoplay>\n",
        "        <source src=\"data:audio/mp3;base64,{b64}\" type=\"audio/mp3\">\n",
        "        </audio>\n",
        "        \"\"\"\n",
        "        st.markdown(md, unsafe_allow_html=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7eqLljoHbxR"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw0VY7tDkdDv",
        "outputId": "c422e6f7-51f7-4c44-fe38-a8502ee1b633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting .env\n"
          ]
        }
      ],
      "source": [
        "%%writefile .env\n",
        "\n",
        "openai_api_key=\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- https://typethepipe.com/post/streamlit-chat-conversational-app-st-chat_message/\n",
        "- https://bijukunjummen.medium.com/chat-application-using-streamlit-and-text-bison-05024f939827"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-Jmsri60LWI",
        "outputId": "156338ba-713d-4c54-b9f3-ef3164ae21ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "\n",
        "from streamlit_float import *\n",
        "from dotenv import load_dotenv\n",
        "# from google.colab import userdata\n",
        "from audio_recorder_streamlit import audio_recorder\n",
        "\n",
        "import llmchain\n",
        "import transcribe\n",
        "import voice\n",
        "\n",
        "load_dotenv()\n",
        "key = os.getenv(\"openai_api_key\")\n",
        "\n",
        "transcribe = transcribe.Transcribe(api_key=key)\n",
        "langchain = llmchain.Langchain(api_key=key)\n",
        "voice = voice.Voice(api_key=key)\n",
        "\n",
        "float_init()\n",
        "\n",
        "def initialize_session_state():\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = [\n",
        "            {\"role\": \"assistant\", \"content\": \"Yoii gess\"}\n",
        "        ]\n",
        "\n",
        "initialize_session_state()\n",
        "\n",
        "st.title(\"COBAGESS\")\n",
        "\n",
        "# Create footer container for the microphone\n",
        "footer_container = st.container()\n",
        "with footer_container:\n",
        "    audio_bytes = audio_recorder()\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.write(message[\"content\"])\n",
        "\n",
        "\n",
        "if audio_bytes:\n",
        "    # Write the audio bytes to a file\n",
        "    with st.spinner(\"Transcribing...\"):\n",
        "\n",
        "        file_path = transcribe.save_file(audio_bytes)\n",
        "        transcript = transcribe.speech_to_text(file_path)\n",
        "\n",
        "        if transcript:\n",
        "            st.session_state.messages.append({\"role\": \"user\", \"content\": transcript})\n",
        "            with st.chat_message(\"user\"):\n",
        "                st.write(transcript)\n",
        "\n",
        "if st.session_state.messages[-1][\"role\"] != \"assistant\":\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        # contoh_response = 'Hello'\n",
        "        # st.write(contoh_response)\n",
        "        with st.spinner(\"Thinking🤔...\"):\n",
        "            data = st.session_state.messages\n",
        "            last_user_index = None\n",
        "            for i, item in enumerate(data):\n",
        "                if item[\"role\"] == \"user\":\n",
        "                    last_user_index = i\n",
        "\n",
        "            # Mengambil nilai content dari peran \"user\" terakhir jika ditemukan\n",
        "            if last_user_index is not None:\n",
        "                last_user_content = data[last_user_index][\"content\"]\n",
        "\n",
        "            response = langchain.chat(last_user_content)\n",
        "\n",
        "            audio_file = voice.text_to_speech(response)\n",
        "            voice.autoplay_audio(audio_file)\n",
        "\n",
        "        st.write(response)\n",
        "            # st.write(file_path)\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "        voice.delete_file()\n",
        "        transcribe.delete_file()\n",
        "\n",
        "\n",
        "# Float the footer container and provide CSS to target it with\n",
        "footer_container.float(\"bottom: 0rem;\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YR7VSjcYnaw",
        "outputId": "d9ad1ff2-f74c-433c-ee92-86c9aa9c55c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.127.41.171"
          ]
        }
      ],
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt & curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GItM9WigYp_G",
        "outputId": "43c15335-b538-4805-ab01-96642d608080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.026s\n",
            "your url is: https://fancy-towns-relate.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc-jTfA4Ytk2",
        "outputId": "2621f3b6-2a8f-4585-c213-b5e963608149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-30 01:43:37--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 52.202.168.65, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13921656 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.28M  19.4MB/s    in 0.7s    \n",
            "\n",
            "2024-04-30 01:43:38 (19.4 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13921656/13921656]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdCuBmZtq4_8",
        "outputId": "d181d046-1776-4060-b195-ea6663d2ed2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ],
      "source": [
        "!unzip ngrok-stable-linux-amd64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "uOKBsRPwq7LS"
      },
      "outputs": [],
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itw_Pf7ZrEcs",
        "outputId": "750dd529-7f50-4bc4-dca4-0ad360f4124f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 293, in load\n",
            "    return loads(fp.read(),\n",
            "  File \"/usr/lib/python3.10/json/__init__.py\", line 346, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.10/json/decoder.py\", line 337, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
          ]
        }
      ],
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    'import sys, json; print(\"Execute the next cell and the go to the following URL: \" +json.load(sys.stdin)[\"tunnels\"][0][\"public_url\"])'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdYncmscrHbz",
        "outputId": "39942937-cd44-4548-a97b-e55037232ccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.80.190:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run /content/app.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAUNjtv_rLyG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
